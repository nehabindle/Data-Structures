{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yelp_Neha_TensorFlow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehabindle/Data-Structures/blob/master/Yelp_Neha_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pifiySPxxOyO",
        "colab_type": "code",
        "outputId": "9376d345-42d3-433c-ce9e-f2033d3f75ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s gdrive/'Team Drives'/'Data Mining Team'/ gdata"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "ln: failed to create symbolic link 'gdata/Data Mining Team': Function not implemented\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "luXf_OC4xj-3",
        "colab_type": "code",
        "outputId": "dc2a0d89-d88c-4cc0-df2d-13aafa907f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_gqIeCczxrMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from tf.keras.models import Sequential  # This does not work!\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L6B4Xnbrxllw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WdZuCaRCx-DJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Importing Libraries from Keras.\n"
      ]
    },
    {
      "metadata": {
        "id": "sV3EeIDyxyKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "loxaQYLfyFod",
        "colab_type": "code",
        "outputId": "bf080421-b515-4e8b-86fe-8635590a1696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Checking the version on Tensorflow\n",
        "tf.__version__\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "aMH6BXckyNPp",
        "colab_type": "code",
        "outputId": "f1f117b0-c38c-4b98-ef52-0e80ab0895bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Checking the version of Keras\n",
        "tf.keras.__version__\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4-tf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "lWI92Z8HyZcS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load Data\n"
      ]
    },
    {
      "metadata": {
        "id": "Pa9qrdmMyeu9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "connection = sqlite3.connect('gdata/yelpHotelData.db')\n",
        "x1 = connection.execute(\"select * FROM review\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T4eFQJ-AyoSS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "description = []\n",
        "Class = []\n",
        "\n",
        "data = x1.fetchmany(100000)\n",
        "\n",
        "for x in data:\n",
        "  description.append(x[3])\n",
        "  Class.append(x[8])\n",
        "trainData = {'Class' : Class, 'Description' : description}\n",
        "df_X = pd.DataFrame(trainData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sXRxY9WYyr0W",
        "colab_type": "code",
        "outputId": "391b9473-4b1c-47c5-f744-d33e80bef495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#Convert NR->N , YR->Y\n",
        "df_X.loc[df_X['Class'] == \"NR\", 'Class'] = \"N\"\n",
        "df_X.loc[df_X['Class'] == \"YR\", 'Class'] = \"Y\"\n",
        "df_X['Class'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N    60436\n",
              "Y    39564\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "0wxZw1G_yvwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "azw9ygo4zI5t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_X['Description'],df_X['Class'], test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEeoIK6zzQqQ",
        "colab_type": "code",
        "outputId": "cf1c23d9-0ac0-41bf-9eaf-c885f51e3761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Checking the shape of Train and Test Data\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70000,) (30000,)\n",
            "(70000,) (30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KHoTHysvznFd",
        "colab_type": "code",
        "outputId": "ebd3df65-a263-4f22-d5ec-00a5e02fef50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Checking the length of train and test data\n",
        "print(\"Train-set size: \", len(X_train))\n",
        "print(\"Test-set size:  \", len(X_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-set size:  70000\n",
            "Test-set size:   30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8mk2YOpd0bnT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Combine into one data-set for some uses below.\n",
        "data_text = X_train + X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B9HMVqX805Vo",
        "colab_type": "code",
        "outputId": "38e1e24a-134b-4521-91c8-ff47dfb9b505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#Printing an example to see how data looks like\n",
        "X_train[1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The only place inside the Loop that you can stay for $55/night. Also, the only place you can have a picnic dinner and get a little frisky on the 17th floor roof and then wake up in your room the next morning to an army of ants going in on your picnic leftovers.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "cyJZjUU-1GZT",
        "colab_type": "code",
        "outputId": "d26dec72-ca51-4189-88be-aef3d6d5ac57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train[1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'N'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "GxZAyxGu1Nkq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenizer\n",
        "A neural network cannot work directly on text-strings so we must convert it somehow. There are two steps in this conversion, the first step is called the \"tokenizer\" which converts words to integers and is done on the data-set before it is input to the neural network. The second step is an integrated part of the neural network itself and is called the \"embedding\"-layer, which is described further below.\n",
        "\n",
        "We may instruct the tokenizer to only use e.g. the 10000 most popular words from the data-set.\n"
      ]
    },
    {
      "metadata": {
        "id": "sLMKCouK1VcM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_words = 10000\n",
        "tokenizer = Tokenizer(num_words=num_words)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQU_A1N01b96",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The tokenizer can then be \"fitted\" to the data-set. This scans through all the text and strips it from unwanted characters such as punctuation, and also converts it to lower-case characters. The tokenizer then builds a vocabulary of all unique words along with various data-structures for accessing the data.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "eYGSiSEb1ebL",
        "colab_type": "code",
        "outputId": "62db887c-e07e-4a9d-9d76-4120982a76e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Tokenization of train data\n",
        "%%time\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.4 s, sys: 40.4 ms, total: 9.44 s\n",
            "Wall time: 9.46 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HlNIXf2a1z0D",
        "colab_type": "code",
        "outputId": "36b7c345-98d4-4da7-921b-ba2c55b92476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Tokenization of test data\n",
        "%%time\n",
        "tokenizer.fit_on_texts(X_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.21 s, sys: 23.9 ms, total: 4.23 s\n",
            "Wall time: 4.24 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lrkQiKCt185i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#set num_words=None above, and then it will automatically be set to the vocabulary-size here.\n",
        "\n",
        "\n",
        "if num_words is None:\n",
        "    num_words = len(tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z5cR1ZEK2JhX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can then inspect the vocabulary that has been gathered by the tokenizer. This is ordered by the number of occurrences of the words in the data-set. These integer-numbers are called word indices or \"tokens\" because they uniquely identify each word in the vocabulary."
      ]
    },
    {
      "metadata": {
        "id": "h89DHq5K2GsI",
        "colab_type": "code",
        "outputId": "fb28302e-b96c-44a2-e02a-7c906cb2ab4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17034
        }
      },
      "cell_type": "code",
      "source": [
        "tokenizer.word_index\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'a': 3,\n",
              " 'i': 4,\n",
              " 'to': 5,\n",
              " 'of': 6,\n",
              " 'was': 7,\n",
              " 'in': 8,\n",
              " 'it': 9,\n",
              " 'is': 10,\n",
              " 'for': 11,\n",
              " 'that': 12,\n",
              " 'but': 13,\n",
              " 'with': 14,\n",
              " 'my': 15,\n",
              " 'you': 16,\n",
              " 'on': 17,\n",
              " 'this': 18,\n",
              " 'they': 19,\n",
              " 'have': 20,\n",
              " 'we': 21,\n",
              " 'not': 22,\n",
              " 'at': 23,\n",
              " 'had': 24,\n",
              " 'so': 25,\n",
              " 'are': 26,\n",
              " 'were': 27,\n",
              " 'good': 28,\n",
              " 'as': 29,\n",
              " 'place': 30,\n",
              " 'be': 31,\n",
              " 'like': 32,\n",
              " 'here': 33,\n",
              " 'me': 34,\n",
              " 'there': 35,\n",
              " 'out': 36,\n",
              " 'all': 37,\n",
              " 'if': 38,\n",
              " 'food': 39,\n",
              " 'just': 40,\n",
              " 'one': 41,\n",
              " 'great': 42,\n",
              " 'get': 43,\n",
              " 'or': 44,\n",
              " \"it's\": 45,\n",
              " 'up': 46,\n",
              " 'from': 47,\n",
              " 'very': 48,\n",
              " 'really': 49,\n",
              " 'some': 50,\n",
              " 'when': 51,\n",
              " 'their': 52,\n",
              " '\\xa0i': 53,\n",
              " 'an': 54,\n",
              " 'our': 55,\n",
              " 'about': 56,\n",
              " 'time': 57,\n",
              " 'go': 58,\n",
              " '\\xa0': 59,\n",
              " 'can': 60,\n",
              " 'which': 61,\n",
              " 'would': 62,\n",
              " 'your': 63,\n",
              " '\\xa0the': 64,\n",
              " 'what': 65,\n",
              " 'back': 66,\n",
              " 'more': 67,\n",
              " 'also': 68,\n",
              " 'service': 69,\n",
              " 'only': 70,\n",
              " 'by': 71,\n",
              " 'nice': 72,\n",
              " 'too': 73,\n",
              " 'no': 74,\n",
              " 'been': 75,\n",
              " 'got': 76,\n",
              " \"don't\": 77,\n",
              " 'other': 78,\n",
              " 'little': 79,\n",
              " 'because': 80,\n",
              " \"i'm\": 81,\n",
              " 'even': 82,\n",
              " 'pretty': 83,\n",
              " 'well': 84,\n",
              " 'will': 85,\n",
              " 'do': 86,\n",
              " 'than': 87,\n",
              " 'has': 88,\n",
              " 'room': 89,\n",
              " 'us': 90,\n",
              " 'them': 91,\n",
              " \"didn't\": 92,\n",
              " 'much': 93,\n",
              " 'people': 94,\n",
              " 'after': 95,\n",
              " 'bar': 96,\n",
              " 'night': 97,\n",
              " \"i've\": 98,\n",
              " 'love': 99,\n",
              " 'he': 100,\n",
              " 'could': 101,\n",
              " 'think': 102,\n",
              " 'best': 103,\n",
              " 'know': 104,\n",
              " 'over': 105,\n",
              " 'did': 106,\n",
              " 'she': 107,\n",
              " 'came': 108,\n",
              " 'way': 109,\n",
              " 'first': 110,\n",
              " 'hotel': 111,\n",
              " 'always': 112,\n",
              " 'two': 113,\n",
              " 'day': 114,\n",
              " 'went': 115,\n",
              " 'off': 116,\n",
              " 'who': 117,\n",
              " 'restaurant': 118,\n",
              " 'better': 119,\n",
              " 'come': 120,\n",
              " '2': 121,\n",
              " 'right': 122,\n",
              " 'going': 123,\n",
              " 'make': 124,\n",
              " 'menu': 125,\n",
              " 'how': 126,\n",
              " 'around': 127,\n",
              " 'try': 128,\n",
              " 'chicken': 129,\n",
              " 'down': 130,\n",
              " 'want': 131,\n",
              " 'few': 132,\n",
              " 'friendly': 133,\n",
              " 'made': 134,\n",
              " 'ordered': 135,\n",
              " 'staff': 136,\n",
              " 'definitely': 137,\n",
              " 'then': 138,\n",
              " 'never': 139,\n",
              " 'see': 140,\n",
              " 'bit': 141,\n",
              " 'order': 142,\n",
              " 'area': 143,\n",
              " '5': 144,\n",
              " 'still': 145,\n",
              " 'though': 146,\n",
              " 'since': 147,\n",
              " 'any': 148,\n",
              " '3': 149,\n",
              " 'while': 150,\n",
              " 'before': 151,\n",
              " 'cheese': 152,\n",
              " 'am': 153,\n",
              " 'small': 154,\n",
              " 'again': 155,\n",
              " 'into': 156,\n",
              " 'new': 157,\n",
              " 'take': 158,\n",
              " 'find': 159,\n",
              " 'most': 160,\n",
              " 'sure': 161,\n",
              " 'say': 162,\n",
              " 'her': 163,\n",
              " 'delicious': 164,\n",
              " 'where': 165,\n",
              " \"wasn't\": 166,\n",
              " 'now': 167,\n",
              " 'next': 168,\n",
              " 'location': 169,\n",
              " 'lot': 170,\n",
              " 'something': 171,\n",
              " 'dinner': 172,\n",
              " 'lunch': 173,\n",
              " \"you're\": 174,\n",
              " 'experience': 175,\n",
              " 'many': 176,\n",
              " 'big': 177,\n",
              " 'table': 178,\n",
              " 'wait': 179,\n",
              " 'sauce': 180,\n",
              " 'ever': 181,\n",
              " 'its': 182,\n",
              " 'being': 183,\n",
              " 'eat': 184,\n",
              " 'bad': 185,\n",
              " 'last': 186,\n",
              " 'thing': 187,\n",
              " 'everything': 188,\n",
              " 'store': 189,\n",
              " '\\xa0it': 190,\n",
              " \"can't\": 191,\n",
              " '4': 192,\n",
              " 'fresh': 193,\n",
              " 'free': 194,\n",
              " 'said': 195,\n",
              " 'give': 196,\n",
              " 'long': 197,\n",
              " 'stars': 198,\n",
              " 'side': 199,\n",
              " 'pizza': 200,\n",
              " 'salad': 201,\n",
              " 'every': 202,\n",
              " 'another': 203,\n",
              " 'drinks': 204,\n",
              " 'things': 205,\n",
              " 'work': 206,\n",
              " 'price': 207,\n",
              " 'enough': 208,\n",
              " 'need': 209,\n",
              " 'feel': 210,\n",
              " 'hot': 211,\n",
              " '1': 212,\n",
              " 'times': 213,\n",
              " 'friend': 214,\n",
              " 'meal': 215,\n",
              " 'minutes': 216,\n",
              " 'looking': 217,\n",
              " '\\xa0we': 218,\n",
              " 'actually': 219,\n",
              " 'wine': 220,\n",
              " 'check': 221,\n",
              " 'amazing': 222,\n",
              " 'kind': 223,\n",
              " '\\xa0they': 224,\n",
              " 'home': 225,\n",
              " 'old': 226,\n",
              " \"that's\": 227,\n",
              " 'worth': 228,\n",
              " 'probably': 229,\n",
              " 'prices': 230,\n",
              " 'took': 231,\n",
              " 'huge': 232,\n",
              " 'wanted': 233,\n",
              " 'yelp': 234,\n",
              " 'thought': 235,\n",
              " 'his': 236,\n",
              " 'drink': 237,\n",
              " 'quite': 238,\n",
              " 'coffee': 239,\n",
              " 'away': 240,\n",
              " '10': 241,\n",
              " 'should': 242,\n",
              " 'beer': 243,\n",
              " 'burger': 244,\n",
              " 'both': 245,\n",
              " 'those': 246,\n",
              " 'friends': 247,\n",
              " \"i'd\": 248,\n",
              " 'chicago': 249,\n",
              " 'parking': 250,\n",
              " 'happy': 251,\n",
              " 'fun': 252,\n",
              " 'selection': 253,\n",
              " 'these': 254,\n",
              " 'sweet': 255,\n",
              " 'super': 256,\n",
              " 'different': 257,\n",
              " 'look': 258,\n",
              " 'awesome': 259,\n",
              " 'stay': 260,\n",
              " 'tasty': 261,\n",
              " 'nothing': 262,\n",
              " 'cool': 263,\n",
              " 'full': 264,\n",
              " 'favorite': 265,\n",
              " 'places': 266,\n",
              " 'perfect': 267,\n",
              " 'found': 268,\n",
              " 'special': 269,\n",
              " 'same': 270,\n",
              " 'tried': 271,\n",
              " 'clean': 272,\n",
              " 'large': 273,\n",
              " 'through': 274,\n",
              " 'why': 275,\n",
              " 'top': 276,\n",
              " 'once': 277,\n",
              " 'meat': 278,\n",
              " 'breakfast': 279,\n",
              " 'bread': 280,\n",
              " 'cream': 281,\n",
              " 'ok': 282,\n",
              " 'chocolate': 283,\n",
              " 'hour': 284,\n",
              " 'sandwich': 285,\n",
              " 'open': 286,\n",
              " 'front': 287,\n",
              " 'spot': 288,\n",
              " 'decent': 289,\n",
              " 'years': 290,\n",
              " 'anything': 291,\n",
              " 'line': 292,\n",
              " 'fries': 293,\n",
              " 'used': 294,\n",
              " 'inside': 295,\n",
              " 'each': 296,\n",
              " 'street': 297,\n",
              " 'dish': 298,\n",
              " 'taste': 299,\n",
              " 'getting': 300,\n",
              " 'maybe': 301,\n",
              " 'recommend': 302,\n",
              " 'asked': 303,\n",
              " 'fried': 304,\n",
              " 'outside': 305,\n",
              " 'couple': 306,\n",
              " 'however': 307,\n",
              " 'city': 308,\n",
              " \"i'll\": 309,\n",
              " 'review': 310,\n",
              " 'flavor': 311,\n",
              " 'visit': 312,\n",
              " 'told': 313,\n",
              " 'star': 314,\n",
              " 'rooms': 315,\n",
              " \"there's\": 316,\n",
              " 'end': 317,\n",
              " 'walk': 318,\n",
              " 'else': 319,\n",
              " 'sushi': 320,\n",
              " 'overall': 321,\n",
              " 'oh': 322,\n",
              " 'beef': 323,\n",
              " 'left': 324,\n",
              " 'during': 325,\n",
              " 'soup': 326,\n",
              " 'hard': 327,\n",
              " 'having': 328,\n",
              " 'half': 329,\n",
              " 'usually': 330,\n",
              " 'items': 331,\n",
              " 'high': 332,\n",
              " 'ice': 333,\n",
              " 'stuff': 334,\n",
              " 'three': 335,\n",
              " 'whole': 336,\n",
              " 'almost': 337,\n",
              " 'without': 338,\n",
              " 'part': 339,\n",
              " 'house': 340,\n",
              " 'loved': 341,\n",
              " 'looked': 342,\n",
              " 'put': 343,\n",
              " 'rice': 344,\n",
              " 'water': 345,\n",
              " 'dessert': 346,\n",
              " 'cheap': 347,\n",
              " 'fish': 348,\n",
              " 'everyone': 349,\n",
              " 'may': 350,\n",
              " 'least': 351,\n",
              " 'stop': 352,\n",
              " 'music': 353,\n",
              " 'http': 354,\n",
              " 'door': 355,\n",
              " 'quality': 356,\n",
              " 'red': 357,\n",
              " 'liked': 358,\n",
              " 'served': 359,\n",
              " 'park': 360,\n",
              " 'atmosphere': 361,\n",
              " 'excellent': 362,\n",
              " 'although': 363,\n",
              " 'course': 364,\n",
              " 'tables': 365,\n",
              " 'close': 366,\n",
              " '\\xa0and': 367,\n",
              " 'decided': 368,\n",
              " 'especially': 369,\n",
              " 'less': 370,\n",
              " 'own': 371,\n",
              " 'done': 372,\n",
              " 'far': 373,\n",
              " 'pork': 374,\n",
              " 'enjoyed': 375,\n",
              " 'town': 376,\n",
              " 'makes': 377,\n",
              " 'such': 378,\n",
              " \"\\xa0it's\": 379,\n",
              " 'yes': 380,\n",
              " 'able': 381,\n",
              " 'hours': 382,\n",
              " 'him': 383,\n",
              " 'quick': 384,\n",
              " 'use': 385,\n",
              " 'enjoy': 386,\n",
              " \"isn't\": 387,\n",
              " 'shop': 388,\n",
              " 'might': 389,\n",
              " 'floor': 390,\n",
              " '6': 391,\n",
              " 'dining': 392,\n",
              " 'must': 393,\n",
              " 'let': 394,\n",
              " 'party': 395,\n",
              " 'dishes': 396,\n",
              " 'week': 397,\n",
              " 'deal': 398,\n",
              " 'coming': 399,\n",
              " 'business': 400,\n",
              " 'seemed': 401,\n",
              " 'server': 402,\n",
              " 'felt': 403,\n",
              " '\\xa0but': 404,\n",
              " 'car': 405,\n",
              " 'com': 406,\n",
              " 'spicy': 407,\n",
              " 'steak': 408,\n",
              " 'lots': 409,\n",
              " 'pay': 410,\n",
              " 'ask': 411,\n",
              " '\\xa0my': 412,\n",
              " 'eating': 413,\n",
              " 'www': 414,\n",
              " 'gave': 415,\n",
              " 'decor': 416,\n",
              " 'someone': 417,\n",
              " 'does': 418,\n",
              " 'okay': 419,\n",
              " '20': 420,\n",
              " \"doesn't\": 421,\n",
              " 'restaurants': 422,\n",
              " '30': 423,\n",
              " 'etc': 424,\n",
              " \"couldn't\": 425,\n",
              " 'show': 426,\n",
              " 'helpful': 427,\n",
              " 'either': 428,\n",
              " 'space': 429,\n",
              " 'called': 430,\n",
              " 'trying': 431,\n",
              " 'until': 432,\n",
              " 'year': 433,\n",
              " 'person': 434,\n",
              " 'guy': 435,\n",
              " 'group': 436,\n",
              " 'fan': 437,\n",
              " 'tea': 438,\n",
              " 'shrimp': 439,\n",
              " 'sit': 440,\n",
              " 'cake': 441,\n",
              " 'call': 442,\n",
              " 'finally': 443,\n",
              " 'needed': 444,\n",
              " 'fact': 445,\n",
              " 'tell': 446,\n",
              " 'days': 447,\n",
              " 'waiting': 448,\n",
              " 'myself': 449,\n",
              " 'late': 450,\n",
              " 'style': 451,\n",
              " 'beautiful': 452,\n",
              " 'instead': 453,\n",
              " 'fine': 454,\n",
              " 'plus': 455,\n",
              " 'busy': 456,\n",
              " 'plate': 457,\n",
              " 'size': 458,\n",
              " 'name': 459,\n",
              " 'saw': 460,\n",
              " 'fantastic': 461,\n",
              " 'guess': 462,\n",
              " '\\xa0this': 463,\n",
              " 'buy': 464,\n",
              " 'yet': 465,\n",
              " '7': 466,\n",
              " '8': 467,\n",
              " 'live': 468,\n",
              " 'expensive': 469,\n",
              " 'fast': 470,\n",
              " 'view': 471,\n",
              " 'started': 472,\n",
              " 'tasted': 473,\n",
              " 'bring': 474,\n",
              " 'reviews': 475,\n",
              " 'keep': 476,\n",
              " 'white': 477,\n",
              " 'family': 478,\n",
              " 'walked': 479,\n",
              " 'extra': 480,\n",
              " 'money': 481,\n",
              " 'trip': 482,\n",
              " 'later': 483,\n",
              " 'cooked': 484,\n",
              " \"they're\": 485,\n",
              " 'point': 486,\n",
              " 'real': 487,\n",
              " 'cold': 488,\n",
              " 'second': 489,\n",
              " 'options': 490,\n",
              " '15': 491,\n",
              " 'comes': 492,\n",
              " 'seems': 493,\n",
              " \"wouldn't\": 494,\n",
              " 'cute': 495,\n",
              " 'easy': 496,\n",
              " 'weekend': 497,\n",
              " 'biz': 498,\n",
              " '…': 499,\n",
              " 'stayed': 500,\n",
              " 'roll': 501,\n",
              " 'care': 502,\n",
              " 'help': 503,\n",
              " 'wonderful': 504,\n",
              " 'reason': 505,\n",
              " 'waitress': 506,\n",
              " 'several': 507,\n",
              " 'expect': 508,\n",
              " '50': 509,\n",
              " 'morning': 510,\n",
              " 'comfortable': 511,\n",
              " 'bacon': 512,\n",
              " 'list': 513,\n",
              " 'early': 514,\n",
              " 'pick': 515,\n",
              " 'local': 516,\n",
              " 'walking': 517,\n",
              " 'glass': 518,\n",
              " 'wrong': 519,\n",
              " 'across': 520,\n",
              " 'ago': 521,\n",
              " 'between': 522,\n",
              " 'ended': 523,\n",
              " 'along': 524,\n",
              " 'green': 525,\n",
              " 'warm': 526,\n",
              " 'downtown': 527,\n",
              " 'light': 528,\n",
              " 'bathroom': 529,\n",
              " 'saturday': 530,\n",
              " 'remember': 531,\n",
              " 'brought': 532,\n",
              " 'job': 533,\n",
              " 'seating': 534,\n",
              " 'crowded': 535,\n",
              " 'set': 536,\n",
              " 'plenty': 537,\n",
              " 'crowd': 538,\n",
              " 'customer': 539,\n",
              " 'interesting': 540,\n",
              " 'past': 541,\n",
              " 'bed': 542,\n",
              " 'offer': 543,\n",
              " 'looks': 544,\n",
              " 'choice': 545,\n",
              " 'gets': 546,\n",
              " 'mind': 547,\n",
              " 'owner': 548,\n",
              " '\\xa0if': 549,\n",
              " 'yummy': 550,\n",
              " 'seen': 551,\n",
              " 'wish': 552,\n",
              " 'hair': 553,\n",
              " 'seem': 554,\n",
              " 'run': 555,\n",
              " 'rolls': 556,\n",
              " 'counter': 557,\n",
              " 'already': 558,\n",
              " 'evening': 559,\n",
              " 'packed': 560,\n",
              " 'seated': 561,\n",
              " \"won't\": 562,\n",
              " 'start': 563,\n",
              " 'life': 564,\n",
              " 'near': 565,\n",
              " 'chips': 566,\n",
              " 'kids': 567,\n",
              " 'regular': 568,\n",
              " 'located': 569,\n",
              " 'type': 570,\n",
              " 'shopping': 571,\n",
              " 'building': 572,\n",
              " 'given': 573,\n",
              " 'perfectly': 574,\n",
              " 'making': 575,\n",
              " 'disappointed': 576,\n",
              " 'totally': 577,\n",
              " 'itself': 578,\n",
              " 'leave': 579,\n",
              " '\\xa0there': 580,\n",
              " 'absolutely': 581,\n",
              " 'thai': 582,\n",
              " 'short': 583,\n",
              " 'four': 584,\n",
              " 'extremely': 585,\n",
              " 'sandwiches': 586,\n",
              " \"you'll\": 587,\n",
              " 'quickly': 588,\n",
              " 'knew': 589,\n",
              " 'french': 590,\n",
              " 'hit': 591,\n",
              " 'sat': 592,\n",
              " 'drive': 593,\n",
              " 'ate': 594,\n",
              " 'brunch': 595,\n",
              " 'arrived': 596,\n",
              " 'impressed': 597,\n",
              " 'cut': 598,\n",
              " 'reasonable': 599,\n",
              " 'often': 600,\n",
              " 'waiter': 601,\n",
              " 'working': 602,\n",
              " 'under': 603,\n",
              " '\\xa0you': 604,\n",
              " 'rather': 605,\n",
              " 'main': 606,\n",
              " 'desk': 607,\n",
              " 'heard': 608,\n",
              " 'mean': 609,\n",
              " 'wedding': 610,\n",
              " 'sometimes': 611,\n",
              " 'head': 612,\n",
              " 'italian': 613,\n",
              " 'today': 614,\n",
              " 'surprised': 615,\n",
              " 'guys': 616,\n",
              " 'dog': 617,\n",
              " 'average': 618,\n",
              " 'mexican': 619,\n",
              " 'sitting': 620,\n",
              " 'man': 621,\n",
              " 'grilled': 622,\n",
              " 'crab': 623,\n",
              " 'sunday': 624,\n",
              " 'event': 625,\n",
              " 'amount': 626,\n",
              " 'chinese': 627,\n",
              " 'problem': 628,\n",
              " 'believe': 629,\n",
              " 'neighborhood': 630,\n",
              " 'girl': 631,\n",
              " 'bbq': 632,\n",
              " 'center': 633,\n",
              " 'flavors': 634,\n",
              " 'priced': 635,\n",
              " 'watch': 636,\n",
              " 'serve': 637,\n",
              " 'lobby': 638,\n",
              " 'potato': 639,\n",
              " 'entire': 640,\n",
              " 'cafe': 641,\n",
              " 'highly': 642,\n",
              " '\\xa0so': 643,\n",
              " 'available': 644,\n",
              " 'burgers': 645,\n",
              " 'black': 646,\n",
              " 'pasta': 647,\n",
              " 'variety': 648,\n",
              " 'world': 649,\n",
              " 'return': 650,\n",
              " 'doing': 651,\n",
              " 'dry': 652,\n",
              " 'club': 653,\n",
              " 'kitchen': 654,\n",
              " 'game': 655,\n",
              " 'potatoes': 656,\n",
              " 'cost': 657,\n",
              " 'stopped': 658,\n",
              " '9': 659,\n",
              " 'five': 660,\n",
              " 'portions': 661,\n",
              " 'ready': 662,\n",
              " 'slow': 663,\n",
              " 'wife': 664,\n",
              " 'la': 665,\n",
              " 'anyone': 666,\n",
              " 'kept': 667,\n",
              " 'behind': 668,\n",
              " 'seriously': 669,\n",
              " 'bite': 670,\n",
              " 'husband': 671,\n",
              " 'w': 672,\n",
              " 'recently': 673,\n",
              " 'others': 674,\n",
              " 'filled': 675,\n",
              " 'friday': 676,\n",
              " 'wall': 677,\n",
              " 'egg': 678,\n",
              " 'dark': 679,\n",
              " 'pieces': 680,\n",
              " 'attentive': 681,\n",
              " 'soon': 682,\n",
              " 'within': 683,\n",
              " 'ones': 684,\n",
              " 'pricey': 685,\n",
              " 'tiny': 686,\n",
              " 'beers': 687,\n",
              " 'hand': 688,\n",
              " 'card': 689,\n",
              " 'seafood': 690,\n",
              " '12': 691,\n",
              " 'patio': 692,\n",
              " 'rest': 693,\n",
              " 'appetizer': 694,\n",
              " 'tacos': 695,\n",
              " 'phone': 696,\n",
              " 'pool': 697,\n",
              " 'middle': 698,\n",
              " 'eggs': 699,\n",
              " 'taking': 700,\n",
              " 'garlic': 701,\n",
              " \"weren't\": 702,\n",
              " 'butter': 703,\n",
              " 'standard': 704,\n",
              " 'idea': 705,\n",
              " '\\xa0a': 706,\n",
              " 'loud': 707,\n",
              " \"haven't\": 708,\n",
              " 'solid': 709,\n",
              " 'soft': 710,\n",
              " 'tip': 711,\n",
              " 'modern': 712,\n",
              " 'sign': 713,\n",
              " 'anyway': 714,\n",
              " 'office': 715,\n",
              " 'birthday': 716,\n",
              " 'including': 717,\n",
              " 'bottle': 718,\n",
              " 'mall': 719,\n",
              " 'hear': 720,\n",
              " 'school': 721,\n",
              " 'together': 722,\n",
              " 'date': 723,\n",
              " 'beans': 724,\n",
              " 'read': 725,\n",
              " 'simple': 726,\n",
              " 'expected': 727,\n",
              " 'crispy': 728,\n",
              " 'specials': 729,\n",
              " 'unique': 730,\n",
              " 'corner': 731,\n",
              " 'thanks': 732,\n",
              " 'option': 733,\n",
              " 'non': 734,\n",
              " 'yourself': 735,\n",
              " 'tomato': 736,\n",
              " 'glad': 737,\n",
              " 'summer': 738,\n",
              " 'bartender': 739,\n",
              " 'appetizers': 740,\n",
              " 'b': 741,\n",
              " 'portion': 742,\n",
              " 'feeling': 743,\n",
              " 'sort': 744,\n",
              " 'add': 745,\n",
              " 'ordering': 746,\n",
              " 'spend': 747,\n",
              " 'note': 748,\n",
              " \"aren't\": 749,\n",
              " 'afternoon': 750,\n",
              " 'art': 751,\n",
              " 'market': 752,\n",
              " \"\\xa0i'm\": 753,\n",
              " 'waited': 754,\n",
              " 'bill': 755,\n",
              " 'charge': 756,\n",
              " 'book': 757,\n",
              " 'gone': 758,\n",
              " 'seat': 759,\n",
              " 'tasting': 760,\n",
              " 'number': 761,\n",
              " 'exactly': 762,\n",
              " 'low': 763,\n",
              " 'sausage': 764,\n",
              " 'miss': 765,\n",
              " 'choose': 766,\n",
              " 'completely': 767,\n",
              " 'entrees': 768,\n",
              " 'cup': 769,\n",
              " 'bowl': 770,\n",
              " 'fruit': 771,\n",
              " 'case': 772,\n",
              " 'salsa': 773,\n",
              " 'ambiance': 774,\n",
              " 'empty': 775,\n",
              " 'change': 776,\n",
              " 'salmon': 777,\n",
              " 'paid': 778,\n",
              " 'minute': 779,\n",
              " 'bought': 780,\n",
              " 'grab': 781,\n",
              " 'stores': 782,\n",
              " 'prepared': 783,\n",
              " 'please': 784,\n",
              " 'tuna': 785,\n",
              " 'offered': 786,\n",
              " 'tv': 787,\n",
              " 'twice': 788,\n",
              " 'joint': 789,\n",
              " 'blue': 790,\n",
              " 'months': 791,\n",
              " 'hotels': 792,\n",
              " 'manager': 793,\n",
              " 'buffet': 794,\n",
              " 'noodles': 795,\n",
              " 'typical': 796,\n",
              " '\\xa0not': 797,\n",
              " '25': 798,\n",
              " 'slightly': 799,\n",
              " 'per': 800,\n",
              " 'lounge': 801,\n",
              " 'boyfriend': 802,\n",
              " 'nights': 803,\n",
              " 'giving': 804,\n",
              " 'hungry': 805,\n",
              " 'piece': 806,\n",
              " 'wow': 807,\n",
              " 'needs': 808,\n",
              " 'recommended': 809,\n",
              " 'customers': 810,\n",
              " 'lovely': 811,\n",
              " 'thin': 812,\n",
              " 'damn': 813,\n",
              " 'based': 814,\n",
              " 'yeah': 815,\n",
              " 'weird': 816,\n",
              " 'level': 817,\n",
              " 'company': 818,\n",
              " 'goes': 819,\n",
              " 'yum': 820,\n",
              " 'entree': 821,\n",
              " 'mouth': 822,\n",
              " 'pleasant': 823,\n",
              " 'onion': 824,\n",
              " 'stand': 825,\n",
              " 'crust': 826,\n",
              " 'worked': 827,\n",
              " 'hate': 828,\n",
              " 'tender': 829,\n",
              " '00': 830,\n",
              " 'walls': 831,\n",
              " 'unless': 832,\n",
              " 'mini': 833,\n",
              " 'bars': 834,\n",
              " 'crazy': 835,\n",
              " 'understand': 836,\n",
              " 'lady': 837,\n",
              " 'due': 838,\n",
              " '\\xa0she': 839,\n",
              " 'class': 840,\n",
              " 'thank': 841,\n",
              " 'bland': 842,\n",
              " 'closed': 843,\n",
              " 'plates': 844,\n",
              " 'baked': 845,\n",
              " 'chain': 846,\n",
              " 'play': 847,\n",
              " 'lobster': 848,\n",
              " 'above': 849,\n",
              " 'mom': 850,\n",
              " 'upon': 851,\n",
              " 'opened': 852,\n",
              " 'flavorful': 853,\n",
              " 'fairly': 854,\n",
              " 'mix': 855,\n",
              " 'onions': 856,\n",
              " 'fancy': 857,\n",
              " 'weeks': 858,\n",
              " 'seats': 859,\n",
              " '\\xa0he': 860,\n",
              " 'whatever': 861,\n",
              " 'shoes': 862,\n",
              " 'taco': 863,\n",
              " 'spent': 864,\n",
              " 'ingredients': 865,\n",
              " 'staying': 866,\n",
              " 'window': 867,\n",
              " 'movie': 868,\n",
              " 'deep': 869,\n",
              " 'section': 870,\n",
              " 'easily': 871,\n",
              " 'stuffed': 872,\n",
              " 'mixed': 873,\n",
              " 'outdoor': 874,\n",
              " 'except': 875,\n",
              " 'airport': 876,\n",
              " 'cash': 877,\n",
              " 'asian': 878,\n",
              " 'choices': 879,\n",
              " 'certainly': 880,\n",
              " 'face': 881,\n",
              " 'reservation': 882,\n",
              " 'lamb': 883,\n",
              " 'talk': 884,\n",
              " '11': 885,\n",
              " 'moved': 886,\n",
              " 'heart': 887,\n",
              " 'chef': 888,\n",
              " 'checked': 889,\n",
              " 'pie': 890,\n",
              " 'immediately': 891,\n",
              " 'basically': 892,\n",
              " 'taken': 893,\n",
              " 'm': 894,\n",
              " 'turned': 895,\n",
              " 'burrito': 896,\n",
              " 'filling': 897,\n",
              " 'shower': 898,\n",
              " 'anywhere': 899,\n",
              " 'products': 900,\n",
              " 'kinda': 901,\n",
              " 'bag': 902,\n",
              " 'oil': 903,\n",
              " 'station': 904,\n",
              " 'move': 905,\n",
              " 'watching': 906,\n",
              " 'tour': 907,\n",
              " 'girls': 908,\n",
              " 'thinking': 909,\n",
              " 'chairs': 910,\n",
              " 'saying': 911,\n",
              " 'playing': 912,\n",
              " 'ribs': 913,\n",
              " 'share': 914,\n",
              " 'talking': 915,\n",
              " 'convenient': 916,\n",
              " 'authentic': 917,\n",
              " 'cozy': 918,\n",
              " 'woman': 919,\n",
              " 'bunch': 920,\n",
              " '\\xa0when': 921,\n",
              " 'running': 922,\n",
              " 'corn': 923,\n",
              " 'literally': 924,\n",
              " 'employees': 925,\n",
              " 'eaten': 926,\n",
              " 'box': 927,\n",
              " 'noticed': 928,\n",
              " 'added': 929,\n",
              " 'wings': 930,\n",
              " 'north': 931,\n",
              " 'says': 932,\n",
              " 'veggies': 933,\n",
              " 'curry': 934,\n",
              " 'greasy': 935,\n",
              " 'duck': 936,\n",
              " 'excited': 937,\n",
              " 'san': 938,\n",
              " 'included': 939,\n",
              " 'toast': 940,\n",
              " 'fabulous': 941,\n",
              " 'hands': 942,\n",
              " 'american': 943,\n",
              " 'foods': 944,\n",
              " 'mine': 945,\n",
              " 'spinach': 946,\n",
              " 'paying': 947,\n",
              " 'sized': 948,\n",
              " 'desserts': 949,\n",
              " 'despite': 950,\n",
              " '\\xa0for': 951,\n",
              " 'eye': 952,\n",
              " 'split': 953,\n",
              " 'usual': 954,\n",
              " 'longer': 955,\n",
              " 'single': 956,\n",
              " 'chance': 957,\n",
              " 'salads': 958,\n",
              " 'salt': 959,\n",
              " 'beach': 960,\n",
              " 'mostly': 961,\n",
              " 'gift': 962,\n",
              " 'hang': 963,\n",
              " 'truly': 964,\n",
              " 'salty': 965,\n",
              " 'perhaps': 966,\n",
              " 'massage': 967,\n",
              " 'touch': 968,\n",
              " 'rich': 969,\n",
              " 'means': 970,\n",
              " 'cupcakes': 971,\n",
              " 'hope': 972,\n",
              " 'otherwise': 973,\n",
              " 'medium': 974,\n",
              " 'alone': 975,\n",
              " 'c': 976,\n",
              " 'received': 977,\n",
              " 'picked': 978,\n",
              " 'mac': 979,\n",
              " 'overpriced': 980,\n",
              " 'clothes': 981,\n",
              " 'st': 982,\n",
              " 'nearby': 983,\n",
              " 'considering': 984,\n",
              " 'dogs': 985,\n",
              " 'meals': 986,\n",
              " 'dance': 987,\n",
              " 'quiet': 988,\n",
              " 'internet': 989,\n",
              " 'true': 990,\n",
              " 'theater': 991,\n",
              " 'dressing': 992,\n",
              " 'takes': 993,\n",
              " 'south': 994,\n",
              " 'sides': 995,\n",
              " 'cupcake': 996,\n",
              " 'rating': 997,\n",
              " 'e': 998,\n",
              " 'professional': 999,\n",
              " 'strip': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "VOzK2GoK2hsu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can then use the tokenizer to convert all texts in the training-set to lists of these tokens."
      ]
    },
    {
      "metadata": {
        "id": "Z4dSCl0F2YmJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "um_Tps-A2t2d",
        "colab_type": "code",
        "outputId": "c43054ec-c820-42b3-ff0f-7659f4ff5fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "X_train[1]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The only place inside the Loop that you can stay for $55/night. Also, the only place you can have a picnic dinner and get a little frisky on the 17th floor roof and then wake up in your room the next morning to an army of ants going in on your picnic leftovers.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "-GKziOCE2zwB",
        "colab_type": "code",
        "outputId": "c73d00d8-c7df-4ac1-8d52-a11aa7ee882d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "np.array(X_train_tokens[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   4,  532,   15, 6561,   33,  186,  530,  190,    7,    1,  110,\n",
              "         57,    4,   24, 1262,   29,   84,  190,    7,   73,  488,    2,\n",
              "        337, 3245,    5,  963,   36,   23,    1,  960,   25,    4,  235,\n",
              "          9,   62,   31,   72,    5,  318,   35,  524,  360,  218,  596,\n",
              "         40,   29,    9,  472, 4889, 2395, 3222,   10,  466,    2,  567,\n",
              "        603,  691,   43,    8,   11,  194, 4677,   19,   68,   20,  114,\n",
              "        202,  624,  165,  567,   60, 8087,    8, 3506, 3322,  110,   21,\n",
              "       1262,    1, 4649, 2841, 1286,   12, 3270, 6521, 1521, 4296, 1696,\n",
              "         21, 1262,    1, 1359,  551, 2451,   17,    1,  110,  390,   21,\n",
              "        889,   36,    1,  712,  751,   17,    1,  489,  390, 2799,    1,\n",
              "       1911,  387,  232,    4,  375,    3,  132,    6,    1,  680,   19,\n",
              "       4147,  412, 6561,  375,    1,  489,  390,   29,   84,  147,    9,\n",
              "        166,   40, 3832,   59,  309,  137,  745,    1,    5,   15,  513,\n",
              "          6,  205,    5,   86,   14,   36,    6,  376, 1070,   51,   21,\n",
              "        209,    5, 2407,   54,  284,   44,  113,    8,    1,  143,  379,\n",
              "        262, 1478,   13,   45,    3,   72,   79, 1134,   14,    3,   42,\n",
              "        471])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "3rToCDDw3mUZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "DhgXmCf73A4k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We also need to convert the texts in the test-set to tokens."
      ]
    },
    {
      "metadata": {
        "id": "Vh1cpnNf290L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HbUNpQnC3Nvl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Padding and Truncating Data¶\n",
        "The Recurrent Neural Network can take sequences of arbitrary length as input, but in order to use a whole batch of data, the sequences need to have the same length. There are two ways of achieving this: (A) Either we ensure that all sequences in the entire data-set have the same length, or (B) we write a custom data-generator that ensures the sequences have the same length within each batch.\n",
        "\n",
        "Solution (A) is simpler but if we use the length of the longest sequence in the data-set, then we are wasting a lot of memory. This is particularly important for larger data-sets.\n",
        "\n",
        "So in order to make a compromise, we will use a sequence-length that covers most sequences in the data-set, and we will then truncate longer sequences and pad shorter sequences.\n",
        "\n",
        "First we count the number of tokens in all the sequences in the data-set."
      ]
    },
    {
      "metadata": {
        "id": "VnonWXPc3VCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_tokens = [len(tokens) for tokens in X_train_tokens + X_test_tokens]\n",
        "num_tokens = np.array(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kE0eW9yh3nqT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The average number of tokens in a sequence is:"
      ]
    },
    {
      "metadata": {
        "id": "l_CvxbHQ33ZT",
        "colab_type": "code",
        "outputId": "a824edf0-6a01-4829-86c6-d4975d717f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.mean(num_tokens)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140.80798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "rPRWwYok39Z-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The maximum number of tokens in a sequence is:"
      ]
    },
    {
      "metadata": {
        "id": "Mw1EM8DA3_-H",
        "colab_type": "code",
        "outputId": "9f861862-fdb3-4bc2-c997-d9e807bbab4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.max(num_tokens)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "-Fdl5ced4JZ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The max number of tokens we will allow is set to the average plus 2 standard deviations."
      ]
    },
    {
      "metadata": {
        "id": "hww_AqTx4MEh",
        "colab_type": "code",
        "outputId": "df00d116-1393-42e0-c19b-7c845e7e5c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "max_tokens = int(max_tokens)\n",
        "max_tokens"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "5ta5aQ8f4Vc-",
        "colab_type": "code",
        "outputId": "54a06a59-8b28-46e9-e41b-496038da5e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.sum(num_tokens < max_tokens) / len(num_tokens)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.95387"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "-gpSwjbO4biG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When padding or truncating the sequences that have a different length, we need to determine if we want to do this padding or truncating 'pre' or 'post'. If a sequence is truncated, it means that a part of the sequence is simply thrown away. If a sequence is padded, it means that zeros are added to the sequence.\n",
        "\n",
        "So the choice of 'pre' or 'post' can be important because it determines whether we throw away the first or last part of a sequence when truncating, and it determines whether we add zeros to the beginning or end of the sequence when padding. This may confuse the Recurrent Neural Network."
      ]
    },
    {
      "metadata": {
        "id": "f6Hsbc8W4hxw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pad = 'pre'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OCJdSfKF4kHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_tokens,\n",
        "                            padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ky_gNfeH5tus",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_tokens,\n",
        "                           padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7woOO57951Kk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have now transformed the training-set into one big matrix of integers (tokens) with this shape:"
      ]
    },
    {
      "metadata": {
        "id": "Nnxp4Gvd56L9",
        "colab_type": "code",
        "outputId": "883769ee-87f2-41cb-fc42-300148358026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_pad.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 369)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "t73XrNAg6B29",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The matrix for the test-set has the same shape:"
      ]
    },
    {
      "metadata": {
        "id": "QVS6Q1HW6DCv",
        "colab_type": "code",
        "outputId": "ba56b798-7f51-40f6-85ab-ca09f020522a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_test_pad.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 369)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "ff2kzZjx6L1Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Change of sequence of tokens into padded sequence.Note that when this is input to the Recurrent Neural Network, then it first inputs a lot of zeros. If we had padded 'post' then it would input the integer-tokens first and then a lot of zeros. This may confuse the Recurrent Neural Network.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1TuD19Tx6XM7",
        "colab_type": "code",
        "outputId": "fe7e5415-d994-4ce4-d397-51e5b0d90399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "np.array(X_train_tokens[1])\n",
        "X_train_pad[1]\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    4,  532,   15, 6561,   33,  186,\n",
              "        530,  190,    7,    1,  110,   57,    4,   24, 1262,   29,   84,\n",
              "        190,    7,   73,  488,    2,  337, 3245,    5,  963,   36,   23,\n",
              "          1,  960,   25,    4,  235,    9,   62,   31,   72,    5,  318,\n",
              "         35,  524,  360,  218,  596,   40,   29,    9,  472, 4889, 2395,\n",
              "       3222,   10,  466,    2,  567,  603,  691,   43,    8,   11,  194,\n",
              "       4677,   19,   68,   20,  114,  202,  624,  165,  567,   60, 8087,\n",
              "          8, 3506, 3322,  110,   21, 1262,    1, 4649, 2841, 1286,   12,\n",
              "       3270, 6521, 1521, 4296, 1696,   21, 1262,    1, 1359,  551, 2451,\n",
              "         17,    1,  110,  390,   21,  889,   36,    1,  712,  751,   17,\n",
              "          1,  489,  390, 2799,    1, 1911,  387,  232,    4,  375,    3,\n",
              "        132,    6,    1,  680,   19, 4147,  412, 6561,  375,    1,  489,\n",
              "        390,   29,   84,  147,    9,  166,   40, 3832,   59,  309,  137,\n",
              "        745,    1,    5,   15,  513,    6,  205,    5,   86,   14,   36,\n",
              "          6,  376, 1070,   51,   21,  209,    5, 2407,   54,  284,   44,\n",
              "        113,    8,    1,  143,  379,  262, 1478,   13,   45,    3,   72,\n",
              "         79, 1134,   14,    3,   42,  471], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "cjoL0cMU6hzx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Tokenizer Inverse Map**\n",
        "\n",
        "For some strange reason, the Keras implementation of a tokenizer does not seem to have the inverse mapping from integer-tokens back to words, which is needed to reconstruct text-strings from lists of tokens. So we make that mapping here."
      ]
    },
    {
      "metadata": {
        "id": "pE2-gWMz6nap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx = tokenizer.word_index\n",
        "inverse_map = dict(zip(idx.values(), idx.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DTEF0gl17EID",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Helper-function for converting a list of tokens back to a string of words."
      ]
    },
    {
      "metadata": {
        "id": "249upoac7G93",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokens_to_string(tokens):\n",
        "    # Map from tokens back to words.\n",
        "    words = [inverse_map[token] for token in tokens if token != 0]\n",
        "    \n",
        "    # Concatenate all words.\n",
        "    text = \" \".join(words)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KpGZa1Bo7JMT",
        "colab_type": "code",
        "outputId": "721d8bb7-ec94-4271-bed9-200e81e47cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#For example, this is the original text from the data-set:\n",
        "\n",
        "X_train[1]\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The only place inside the Loop that you can stay for $55/night. Also, the only place you can have a picnic dinner and get a little frisky on the 17th floor roof and then wake up in your room the next morning to an army of ants going in on your picnic leftovers.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "CX83b1hj7UM8",
        "colab_type": "code",
        "outputId": "8afd3b99-759a-448e-dd97-ec294e11e748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "tokens_to_string(X_train_tokens[1])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i brought my niece here last saturday \\xa0it was the first time i had visited as well \\xa0it was too cold and almost rainy to hang out at the beach so i thought it would be nice to walk there along park \\xa0we arrived just as it started raining adult admission is 7 and kids under 12 get in for free \\xa0apparently they also have day every sunday where kids can participate in artist lead first we visited the children's gallery downstairs that featured pin hole photography \\xa0then we visited the california seen exhibit on the first floor we checked out the modern art on the second floor \\xa0although the collection isn't huge i enjoyed a few of the pieces they displayed \\xa0my niece enjoyed the second floor as well since it wasn't just paintings \\xa0 i'll definitely add the to my list of things to do with out of town guests when we need to kill an hour or two in the area \\xa0it's nothing spectacular but it's a nice little museum with a great view\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "Q1lwXbDO7nTq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create the Recurrent Neural Network**\n"
      ]
    },
    {
      "metadata": {
        "id": "aUlcYzSR7war",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOUcjmQA70D0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zEiHGsop7243",
        "colab_type": "code",
        "outputId": "e3bf13e1-5e9c-4078-96b4-e3925c58c4af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "model.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_size,\n",
        "                    input_length=max_tokens,\n",
        "                    name='layer_embedding'))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RSxS0bQ4762I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Adding the gated GRU\n",
        "model.add(GRU(units=16, return_sequences=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3HEo-f3j8DP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Adding the second GRU with 8 output units\n",
        "model.add(GRU(units=8, return_sequences=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BuYNAtaR8Lel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This code adds the third and final GRU with 4 output units. This will be followed by a dense-layer, so it should only give the final output of the GRU and not a whole sequence of outputs.\n",
        "\n",
        "model.add(GRU(units=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "43DIqzSy8YrQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "dd a fully-connected / dense layer which computes a value between 0.0 and 1.0 that will be used as the classification output."
      ]
    },
    {
      "metadata": {
        "id": "Iuy0Ns1Z8elX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5tMNpwiZ8jQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Adam optimizer with the given learning-rate.\n",
        "optimizer = Adam(lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xd22QhtM8pir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Compile the Keras model so it is ready for training.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKp48z8I8t-O",
        "colab_type": "code",
        "outputId": "aae1110c-e43f-4337-ae72-1eaae9ccc002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer_embedding (Embedding)  (None, 369, 8)            80000     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 369, 16)           1200      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 369, 8)            600       \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 4)                 156       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 81,961\n",
            "Trainable params: 81,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aPleqvXQ8zJT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train the Recurrent Neural Network**\n",
        "\n",
        "We can now train the model. Note that we are using the data-set with the padded sequences. We use 5% of the training-set as a small validation-set, so we have a rough idea whether the model is generalizing well or if it is perhaps over-fitting to the training-set."
      ]
    },
    {
      "metadata": {
        "id": "kjcKGk7lZ-tZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print(y_train.loc[y_train['Class'] == \"N\"])\n",
        "def mapToBinary(x):\n",
        "  if x == 'Y':\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "y_train_bin = list(map(mapToBinary, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iEzDIMOP5Bxk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_bin = list(map(mapToBinary, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KvcbfmwK87I_",
        "colab_type": "code",
        "outputId": "5243ff73-ab2b-4646-9c51-6e14ce95778e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model.fit(X_train_pad, y_train_bin,\n",
        "          validation_split=0.05, epochs=1, batch_size=64)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 66500 samples, validate on 3500 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "66500/66500 [==============================] - 1552s 23ms/sample - loss: 0.6627 - acc: 0.6112 - val_loss: 0.6273 - val_acc: 0.6409\n",
            "CPU times: user 36min 1s, sys: 2min 7s, total: 38min 9s\n",
            "Wall time: 25min 56s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f30714254a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "O46QrFzJN6sx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('gdata/my_model.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N1QAHnkh5DqT",
        "colab_type": "code",
        "outputId": "2debe469-453b-4857-a7c5-35a860684877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "X_test_pad"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    4,  102,   22],\n",
              "       [   0,    0,    0, ...,   17,    1,  696],\n",
              "       [   0,    0,    0, ...,  473,   32, 1174],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,   57,   35,   73],\n",
              "       [   0,    0,    0, ...,  475,  151, 2051],\n",
              "       [   0,    0,    0, ...,    6,  220,  467]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "xYLE7XGWN5CK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1JqTZnJ_34XV",
        "colab_type": "code",
        "outputId": "c7871928-2f89-4077-c9cf-dba46e4161fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Performance on Test-Set\n",
        "# Now that the model has been trained we can calculate its classification accuracy on the test-set.\n",
        "\n",
        "%%time\n",
        "result = model.evaluate(X_test_pad, y_test_bin)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000/30000 [==============================] - 553s 18ms/sample - loss: 0.6369 - acc: 0.6298\n",
            "CPU times: user 14min 25s, sys: 1min 15s, total: 15min 40s\n",
            "Wall time: 9min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YiGfmD2z6dvj",
        "colab_type": "code",
        "outputId": "9bac7a81-8a35-4d2f-a61e-0463dfcbdbf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: {0:.2%}\".format(result[1]))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 62.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2cUYR-bmdkS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "87de9329-3e89-4985-d455-8cb9833b6c7a"
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test_pad)\n",
        "predictions_bin = list(map(lambda x: 1 if x>=0.5 else 0, predictions))\n",
        "predictions_bin\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.classification_report(y_test_bin, predictions_bin))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.90      0.75     18123\n",
            "           1       0.58      0.22      0.32     11877\n",
            "\n",
            "   micro avg       0.63      0.63      0.63     30000\n",
            "   macro avg       0.61      0.56      0.53     30000\n",
            "weighted avg       0.62      0.63      0.58     30000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pML5erMwRN6x",
        "colab_type": "code",
        "outputId": "7bda4af1-60b7-4515-ea09-1a005d84ec72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# #In order to show an example of mis-classified text, we first calculate the predicted sentiment for the first 1000 texts in the test-set.\n",
        "# %%time\n",
        "# y_pred = model.predict(x=X_test_pad[0:1000])\n",
        "# y_pred = y_pred.T[0]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 30.2 s, sys: 2.85 s, total: 33.1 s\n",
            "Wall time: 19.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fzVw7AkDcvdi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #These predicted numbers fall between 0.0 and 1.0. We use a cutoff / threshold and say that all values above 0.5 are taken to be 1.0 \n",
        "# #and all values below 0.5 are taken to be 0.0. This gives us a predicted \"class\" of either 0.0 or 1.0.\n",
        "# cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nUBS2JTGRdx6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #he true \"class\" for the first 1000 texts in the test-set are needed for comparison.\n",
        "\n",
        "# cls_true = np.array(y_test[0:1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xx4Xd0gJc79E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #We can then get indices for all the texts that were incorrectly classified by comparing all the \"classes\" of these two arrays\n",
        "# incorrect = np.where(cls_pred != cls_true)\n",
        "# incorrect = incorrect[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vOnVcCuHdEi-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Of the 1000 texts used, how many were mis-classified?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2d74LLuKcbTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# y_test_bin = list(map(mapToBinary, y_test))\n",
        "\n",
        "# predictions = model.predict(X_test_pad)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bqiwr4Nteumo",
        "colab_type": "code",
        "outputId": "cd06d194-016a-4ba9-eec9-b90dc719d142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "cell_type": "code",
      "source": [
        "# predictions_bin = list(map(lambda x: 1 if x>=0.5 else 0, predictions))\n",
        "# predictions_bin\n",
        "\n",
        "# from sklearn import metrics\n",
        "\n",
        "# print(metrics.classification_report(y_test_bin, predictions_bin))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.92      0.84      2297\n",
            "           1       0.38      0.17      0.23       703\n",
            "\n",
            "   micro avg       0.74      0.74      0.74      3000\n",
            "   macro avg       0.58      0.54      0.54      3000\n",
            "weighted avg       0.69      0.74      0.70      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BlnXL3ufez9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "def6c182-4b52-44e4-f955-f1c5ddf73ab0"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}